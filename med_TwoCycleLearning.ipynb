{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import copy\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from torch.optim import lr_scheduler\n",
    "from random import random\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage import color\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.utils import shuffle\n",
    "from kmeans_pytorch import kmeans, kmeans_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('max_colwidth', None)\n",
    "train_path=pd.read_csv('./MURA-v1.1/train_image_paths.csv', header=None)\n",
    "train_path = shuffle(train_path)\n",
    "train_path = train_path.reset_index()\n",
    "train_path = train_path.drop('index',axis=1)\n",
    "tmp=train_path[0].copy()\n",
    "def generate_part(x):\n",
    "    x=x.split('/')\n",
    "    x=x[2]\n",
    "    x=x.split('_')\n",
    "    x=x[1]\n",
    "    return x\n",
    "tmp=tmp.apply(generate_part)\n",
    "train_path['part']=tmp\n",
    "train_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path['part'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wrist_path = train_path[train_path.part == 'WRIST']#wrist\n",
    "train_wrist_path=train_wrist_path.reset_index()\n",
    "train_wrist_path.drop(['index','part'],axis=1,inplace=True)\n",
    "train_wrist_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path=pd.read_csv('./MURA-v1.1/valid_image_paths.csv', header=None)\n",
    "test_path = shuffle(test_path)\n",
    "test_path = test_path.reset_index()\n",
    "test_path = test_path.drop('index',axis=1)\n",
    "tmp=test_path[0].copy()\n",
    "tmp=tmp.apply(generate_part)\n",
    "test_path['part']=tmp\n",
    "test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wrist_path = test_path[test_path.part == 'WRIST']\n",
    "test_wrist_path=test_wrist_path.reset_index()\n",
    "test_wrist_path.drop(['index','part'],axis=1,inplace=True)\n",
    "test_wrist_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_path=train_wrist_path[0][1].split('/')\n",
    "sep_path[-2][-8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(train_wrist_path[0][0])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=color.rgb2gray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=img*255\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=img.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq = cv2.equalizeHist(img)\n",
    "plt.imshow(eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabel_ratio=50\n",
    "max_data_num=len(train_wrist_path)\n",
    "labeled_index=int(max_data_num/unlabel_ratio)\n",
    "labeled_df=train_wrist_path[:labeled_index]\n",
    "unlabeled_df=train_wrist_path[labeled_index:]\n",
    "unlabeled_df=unlabeled_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label(addr):\n",
    "    addr=addr.split('/')\n",
    "    if(addr[-2][-8:]=='positive'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "tmp=labeled_df[0]\n",
    "tmp=tmp.apply(generate_label)\n",
    "labeled_df[1]=tmp\n",
    "labeled_data_label=np.array(tmp)\n",
    "\n",
    "tmp=test_wrist_path[0]\n",
    "tmp=tmp.apply(generate_label)\n",
    "test_wrist_path[1]=tmp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(labeled_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class xray_dataset(Dataset):#繼承Dataset物件\n",
    "    def __init__(self,df,labeled):\n",
    "        super().__init__()\n",
    "        self.df=df\n",
    "        self.labeled=labeled\n",
    "    def __getitem__(self,index):\n",
    "        #通常會在get item裡面實作data augmentation、transformation\n",
    "        img=cv2.imread(self.df[0][index])\n",
    "        img=color.rgb2gray(img)\n",
    "        img=img*255\n",
    "        img=img.astype('uint8')\n",
    "        img=cv2.equalizeHist(img)\n",
    "        if(img.shape[0]>img.shape[1]):#make image's long side parallel with x-axis\n",
    "            if(random()>0.5):\n",
    "                img=cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "            else:\n",
    "                img=cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        img = cv2.resize(img, (350, 200), interpolation=cv2.INTER_CUBIC)#width,height\n",
    "        img=np.array([img]).astype('float32')#from 2 dim to 3 dim\n",
    "#         img=cv2.resize(img, None,fx=0.4,fy=0.4, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        label=0\n",
    "        if(self.labeled==False):\n",
    "            label=-1\n",
    "        else:\n",
    "            label=self.df[1][index]\n",
    "        label=np.array(label).astype('float32')\n",
    "        return img,label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "labeled_dataset=xray_dataset(labeled_df,labeled=True)\n",
    "unlabeled_dataset=xray_dataset(unlabeled_df,labeled=False)\n",
    "train_dataset=xray_dataset(train_wrist_path,labeled=False)#used to train K-means\n",
    "test_dataset=xray_dataset(test_wrist_path,labeled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(unlabeled_dataset[0][0][0])#[data index][img/label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(models.resnet.ResNet):\n",
    "    def __init__(self,block,layers,num_classes):\n",
    "        super(model, self).__init__(block,layers,num_classes)\n",
    "        self.inplanes=64\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.conv1.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res = model(block=models.resnet.Bottleneck,layers=[3, 4, 23, 3],num_classes=2)\n",
    "model_res.fc = nn.Sequential(nn.Flatten(),                \n",
    "                                nn.Linear(in_features=2048,out_features=1000),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Linear(in_features=1000,out_features=100),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Linear(in_features=100,out_features=2),\n",
    "                                nn.Sigmoid()\n",
    "        )\n",
    "for param in model_res.parameters():\n",
    "    param.requires_grad = True\n",
    "model_res=model_res.float()\n",
    "if torch.cuda.is_available():\n",
    "    model_res=model_res.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_dataloader=DataLoader(labeled_dataset,batch_size=10,shuffle=False)\n",
    "unlabeled_dataloader=DataLoader(unlabeled_dataset,batch_size=10,shuffle=False)\n",
    "train_dataloader=DataLoader(train_dataset,batch_size=1,shuffle=False)\n",
    "test_dataloader=DataLoader(test_dataset,batch_size=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x,y,alpha=1.0):\n",
    "    if alpha>0:\n",
    "        lam=np.random.beta(alpha,alpha)\n",
    "    else:\n",
    "        lam=1\n",
    "    batch_size=x.size()[0]\n",
    "    if torch.cuda.is_available():\n",
    "        index=torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index=torch.randperm(batch_size)\n",
    "    \n",
    "    mixed_x=lam*x+(1-lam)*x[index,:]\n",
    "    y_a,y_b=y,y[index]\n",
    "    return mixed_x,y_a,y_b,lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixed_criterion(criterion,pred,y_a,y_b,lam):\n",
    "    return lam*criterion(pred,y_a)+(1-lam)*criterion(pred,y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_res,data_loader,test_dataloader,binary,epoch=20,learning_rate=1e-4,wd=3e-3,lr_sche_step=7,use_mixup=False):\n",
    "    metrics_list={'train_loss':[],'test_loss':[]}\n",
    "    criterionBCE=nn.BCELoss()\n",
    "    criterionCE=nn.CrossEntropyLoss()\n",
    "    optimizer=torch.optim.Adam(model_res.parameters(),lr=learning_rate,weight_decay=wd)\n",
    "    scheduler=lr_scheduler.StepLR(optimizer,step_size=lr_sche_step,gamma=0.1)  \n",
    "    best_f1=0.0\n",
    "    best_model=copy.deepcopy(model_res.state_dict())\n",
    "    total=len(data_loader.dataset)\n",
    "    for i in range(epoch):\n",
    "        print(\"epoch:\",i)\n",
    "        model_res.train()\n",
    "        success=0\n",
    "        loss_sum=0\n",
    "        total_iteration=0.0\n",
    "        for idx,(data,label) in enumerate(tqdm(data_loader)):   \n",
    "            total_iteration+=1\n",
    "            data.requires_grad_(True)\n",
    "            if torch.cuda.is_available():\n",
    "                data=data.cuda()\n",
    "                label=label.cuda()\n",
    "            \n",
    "            if(use_mixup):\n",
    "                data,label_a,label_b,lam=mixup_data(data,label)\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            output=model_res(data)\n",
    "            if(binary):\n",
    "                if(use_mixup):\n",
    "                    loss=mixed_criterion(criterionBCE,output[:,0],label_a,label_b,lam)\n",
    "                else:\n",
    "                    loss=criterionBCE(output[:,0],label)\n",
    "            else:\n",
    "                if(use_mixup):\n",
    "                    label_a=label_a.long()\n",
    "                    label_b=label_b.long()\n",
    "                    loss=mixed_criterion(criterionCE,output,label_a,label_b,lam)\n",
    "                else:\n",
    "                    label=label.long()\n",
    "                    loss=criterionCE(output,label)\n",
    "            loss.backward()\n",
    "            loss.detach_()\n",
    "            loss_sum+=loss\n",
    "            optimizer.step()\n",
    "            if(binary):\n",
    "                preds = (output>0.5)\n",
    "    #             print(\"preds\",preds.type(torch.int)[:,0])\n",
    "                success+=torch.sum(preds.type(torch.int)[:,0]==label.type(torch.int))\n",
    "            else:\n",
    "                _,preds=torch.max(output,1)\n",
    "                label=label.long()\n",
    "                success+=torch.sum(preds==label)\n",
    "        print(\"training_accuracy:{:.3f}\".format(float(success) / float(total)))\n",
    "        metrics_list['train_loss'].append(loss_sum/total_iteration)\n",
    "        cur_f1,test_loss=test(model_res,test_dataloader,binary)\n",
    "        metrics_list['test_loss'].append(test_loss)\n",
    "        if(cur_f1>best_f1):\n",
    "            best_f1=cur_f1\n",
    "            best_model=copy.deepcopy(model_res.state_dict())\n",
    "        scheduler.step()\n",
    "        \n",
    "    return best_model,model_res,metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model_res,data_loader,binary):\n",
    "    model_res.eval()\n",
    "    criterionBCE=nn.BCELoss()\n",
    "    criterionCE=nn.CrossEntropyLoss()\n",
    "    total=len(data_loader.dataset)\n",
    "    success=0\n",
    "    loss_sum=0\n",
    "    total_iteration=0.0\n",
    "    prec_sum = 0.0\n",
    "    recall_sum =0.0\n",
    "    f1_sum = 0.0 \n",
    "    for idx,(data,label) in enumerate(tqdm(data_loader)):\n",
    "        total_iteration+=1\n",
    "        if torch.cuda.is_available():\n",
    "            data=data.cuda()\n",
    "            label=label.cuda()\n",
    "        output=model_res(data)\n",
    "        if(binary):\n",
    "            loss=criterionBCE(output[:,0],label)\n",
    "        else:\n",
    "            label=label.long()\n",
    "            loss=criterionCE(output,label)\n",
    "        loss_sum+=loss\n",
    "        if(binary):\n",
    "            preds = (output>0.5)\n",
    "            success+=torch.sum(preds.type(torch.int)[:,0]==label.type(torch.int))\n",
    "        else:\n",
    "            _,preds=torch.max(output,1)\n",
    "            success+=torch.sum(preds==label)\n",
    "        y = np.array(label.cpu())\n",
    "        pred = np.array(preds.cpu())\n",
    "        prec_sum += metrics.precision_score(y, pred,average='macro',zero_division=1)\n",
    "        recall_sum += metrics.recall_score(y, pred,average='macro',zero_division=1)\n",
    "        f1_sum += metrics.f1_score(y, pred,average='macro',zero_division=1)\n",
    "    acc=float(success) / float(total)\n",
    "    print(\"testing_accuracy:{:.3f}\".format(acc))\n",
    "    print(\"testing_loss:{:.3f}\".format(loss_sum/total_iteration))\n",
    "    print(\"testing_precision:{:.3f}\".format(prec_sum/total_iteration))\n",
    "    print(\"testing_recall:{:.3f}\".format(recall_sum/total_iteration))\n",
    "    print(\"testing_f1:{:.3f}\".format(f1_sum/total_iteration))\n",
    "    return f1_sum/total_iteration,loss_sum/total_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=40\n",
    "model_best,model_res,metrics_list=train(model_res,labeled_dataloader,test_dataloader,binary=False,epoch=epoch,wd=3e-3,lr_sche_step=20,use_mixup=False)\n",
    "plt.plot(np.arange(1,epoch+1,1), metrics_list['train_loss'], '-',color='blue',label=\"train\")\n",
    "plt.plot(np.arange(1,epoch+1,1), metrics_list['test_loss'], '-',color='orange',label=\"test\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res.load_state_dict(model_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model_res,test_dataloader,binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_feature_vector(model,dataloader):\n",
    "    vector_list=[]\n",
    "    for (data,label) in tqdm(dataloader):\n",
    "        if(torch.cuda.is_available()):\n",
    "            data=data.cuda()\n",
    "        output=model(data)\n",
    "        output=output.cpu()\n",
    "        output=np.array(output)\n",
    "        vector_list.append(output[0,:,0,0])\n",
    "    return vector_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model_and_reset_fc(model,output_dim):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.fc= nn.Sequential(nn.Flatten(),                \n",
    "                            nn.Linear(in_features=2048,out_features=1000),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Linear(in_features=1000,out_features=100),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Linear(in_features=100,out_features=output_dim),\n",
    "                            nn.Sigmoid()\n",
    "                            )\n",
    "    model.fc.requires_grad=True\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class knn_dataset(Dataset):\n",
    "    def __init__(self,df,label):\n",
    "        super().__init__()\n",
    "        self.df=df\n",
    "        self.label=label\n",
    "    def __getitem__(self,index):\n",
    "        img=cv2.imread(self.df[0][index])\n",
    "        img=color.rgb2gray(img)\n",
    "        img=img*255\n",
    "        img=img.astype('uint8')\n",
    "        img=cv2.equalizeHist(img)\n",
    "        if(img.shape[0]>img.shape[1]):#make image's long side parallel with x-axis\n",
    "            if(random()>0.5):\n",
    "                img=cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "            else:\n",
    "                img=cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        img = cv2.resize(img, (350, 200), interpolation=cv2.INTER_CUBIC)#width,height\n",
    "        img=np.array([img]).astype('float32')#from 2 dim to 3 dim\n",
    "        label=self.label[index]\n",
    "        label=np.array(label).astype('float32')\n",
    "        return img,label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_cycle_training(model_res,cycle_num,epoch):\n",
    "    for i in range(cycle_num):\n",
    "        res_conv=nn.Sequential(*list(model_res.children())[:-1])#model_res without the FC layer\n",
    "        feature_vector=generate_feature_vector(res_conv,train_dataloader)\n",
    "        feature_vector_array=np.array(feature_vector)\n",
    "        feature_vector_array=torch.from_numpy(feature_vector_array)\n",
    "        model_res=freeze_model_and_reset_fc(model_res,output_dim=50)\n",
    "        model_res=model_res.cuda()\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device('cuda:0')\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "            \n",
    "        cluster_ids_x, cluster_centers = kmeans(\n",
    "            X=feature_vector_array, num_clusters=10, distance='euclidean', device=device\n",
    "        )\n",
    "        data_len=len(train_wrist_path)\n",
    "        data_index=int(data_len*0.8)\n",
    "        knn_train_data=knn_dataset(train_wrist_path[:data_index],cluster_ids_x[:data_index])\n",
    "        knn_test_data=knn_dataset(train_wrist_path[data_index:].reset_index(),cluster_ids_x[data_index:])\n",
    "        knn_train_loader=DataLoader(knn_train_data,batch_size=10,shuffle=True)\n",
    "        knn_test_loader=DataLoader(knn_test_data,batch_size=10,shuffle=True)\n",
    "\n",
    "        model_best,model_res,metrics_list=train(model_res,knn_train_loader,knn_test_loader,binary=False,epoch=int(epoch/3),wd=0)\n",
    "        plt.plot(np.arange(1,int(epoch/3)+1,1), metrics_list['train_loss'], '-',color='blue',label=\"train\")\n",
    "        plt.plot(np.arange(1,int(epoch/3)+1,1), metrics_list['test_loss'], '-',color='orange',label=\"test\")\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        # plt.savefig(self.log_dir/'metrics.png')\n",
    "        plt.show()\n",
    "        \n",
    "        for param in model_res.parameters():\n",
    "            param.requires_grad = True\n",
    "        model_best,model_res,metrics_list=train(model_res,knn_train_loader,knn_test_loader,binary=False,epoch=epoch,learning_rate=1e-4,wd=0,lr_sche_step=7)\n",
    "        plt.plot(np.arange(1,epoch+1,1), metrics_list['train_loss'], '-',color='blue',label=\"train\")\n",
    "        plt.plot(np.arange(1,epoch+1,1), metrics_list['test_loss'], '-',color='orange',label=\"test\")\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        # plt.savefig(self.log_dir/'metrics.png')\n",
    "        plt.show()\n",
    "    return model_best,model_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model_best,model_res=first_cycle_training(model_res,2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_cycle_training(model_res,cycle_num,epoch,test_dataloader):\n",
    "    for i in range(cycle_num):\n",
    "        res_conv=nn.Sequential(*list(model_res.children())[:-1])#model_res without the FC layer\n",
    "        labeled_dataloader=DataLoader(labeled_dataset,batch_size=1,shuffle=False)\n",
    "        labeled_feature_vector=generate_feature_vector(res_conv,labeled_dataloader)\n",
    "        labeled_feature_vector_array=np.array(labeled_feature_vector)\n",
    "        labeled_feature_vector_array=torch.from_numpy(labeled_feature_vector_array)\n",
    "        \n",
    "        unlabeled_dataloader=DataLoader(unlabeled_dataset,batch_size=1,shuffle=False)\n",
    "        unlabeled_feature_vector=generate_feature_vector(res_conv,unlabeled_dataloader)\n",
    "        unlabeled_feature_vector_array=np.array(unlabeled_feature_vector)\n",
    "        unlabeled_feature_vector_array=torch.from_numpy(unlabeled_feature_vector_array)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device('cuda:0')\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "        \n",
    "        knn=KNeighborsClassifier(n_neighbors=5)\n",
    "        knn.fit(labeled_feature_vector_array,labeled_data_label)\n",
    "        pseudo_label=knn.predict(unlabeled_feature_vector_array)\n",
    "        pseudo_labeled_df=train_wrist_path\n",
    "        pseudo_labeled_df[1]=pd.DataFrame(np.concatenate([labeled_data_label,pseudo_label]))\n",
    "        pseudo_labeled_dataset=xray_dataset(pseudo_labeled_df,labeled=True)\n",
    "        pseudo_labeled_dataloader=DataLoader(pseudo_labeled_dataset,batch_size=10,shuffle=False)\n",
    "        \n",
    "        model_res=freeze_model_and_reset_fc(model_res,output_dim=2)\n",
    "        model_res=model_res.cuda()\n",
    "        \n",
    "        data_len=len(train_wrist_path)\n",
    "        data_index=int(data_len*0.8)\n",
    "\n",
    "        model_best,model_res,metrics_list=train(model_res,pseudo_labeled_dataloader,test_dataloader,binary=False,epoch=int(epoch/3),wd=0)\n",
    "        plt.plot(np.arange(1,int(epoch/3)+1,1), metrics_list['train_loss'], '-',color='blue',label=\"train\")\n",
    "        plt.plot(np.arange(1,int(epoch/3)+1,1), metrics_list['test_loss'], '-',color='orange',label=\"test\")\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        # plt.savefig(self.log_dir/'metrics.png')\n",
    "        plt.show()\n",
    "        \n",
    "        for param in model_res.parameters():\n",
    "            param.requires_grad = True\n",
    "        model_best,model_res,metrics_list=train(model_res,pseudo_labeled_dataloader,test_dataloader,binary=False,epoch=epoch,learning_rate=1e-4,wd=5e-3,lr_sche_step=7)\n",
    "        plt.plot(np.arange(1,epoch+1,1), metrics_list['train_loss'], '-',color='blue',label=\"train\")\n",
    "        plt.plot(np.arange(1,epoch+1,1), metrics_list['test_loss'], '-',color='orange',label=\"test\")\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        # plt.savefig(self.log_dir/'metrics.png')\n",
    "        plt.show()\n",
    "    return model_best,model_res\n",
    "second_model_best,model_res=second_cycle_training(model_res,2,10,test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res.load_state_dict(second_model_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model_res,test_dataloader,binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=40\n",
    "model_best,model_res,metrics_list=train(model_res,labeled_dataloader,test_dataloader,binary=False,epoch=epoch,wd=3e-3,lr_sche_step=20,use_mixup=False)\n",
    "plt.plot(np.arange(1,epoch+1,1), metrics_list['train_loss'], '-',color='blue',label=\"train\")\n",
    "plt.plot(np.arange(1,epoch+1,1), metrics_list['test_loss'], '-',color='orange',label=\"test\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "# plt.savefig(self.log_dir/'metrics.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res.load_state_dict(model_best)\n",
    "test(model_res,test_dataloader,binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mixup = model(block=models.resnet.Bottleneck,layers=[3, 4, 23, 3],num_classes=2)\n",
    "model_mixup.fc = nn.Sequential(nn.Flatten(),                \n",
    "                                nn.Linear(in_features=2048,out_features=1000),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Linear(in_features=1000,out_features=100),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Linear(in_features=100,out_features=2),\n",
    "                                nn.Sigmoid()\n",
    "        )\n",
    "for param in model_mixup.parameters():\n",
    "    param.requires_grad = True\n",
    "model_mixup=model_mixup.float()\n",
    "if torch.cuda.is_available():\n",
    "    model_mixup=model_mixup.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=80\n",
    "model_mixup_best,model_mixup,metrics_list=train(model_mixup,labeled_dataloader,test_dataloader,binary=False,epoch=epoch,wd=3e-3,lr_sche_step=25,use_mixup=False)\n",
    "plt.plot(np.arange(1,epoch+1,1), metrics_list['train_loss'], '-',color='blue',label=\"train\")\n",
    "plt.plot(np.arange(1,epoch+1,1), metrics_list['test_loss'], '-',color='orange',label=\"test\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "# plt.savefig(self.log_dir/'metrics.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mixup.load_state_dict(model_mixup_best)\n",
    "test(model_mixup,test_dataloader,binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}